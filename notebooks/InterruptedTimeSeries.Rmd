---
title: "How Does the Adoption of Cursor Affect Software Development Productivity?"
author: "Hao He"
date: "2025-04-17"
output: html_document
---

## Methodology Overview

### Modeling Strategy

We have two possible modeling strategies: **model per user** or **model per repository**.

- The former represents individual-level micro outcomes. It makes more sense to assume that the user adding or modifying a cursor configuration file is definitely using Cursor. However, individual-level outcomes may be more noisy. For example, one can give up contribution entirely in a specific time period for other reasons.
- The latter represents project-level macro outcomes, but is potentially confounded by the extent of Cursor adoption in each time period. It is possible that the project has 100 developers but only one of them adopts Cursor. The macro outcome is also potentially confounded by the size/resource of the team in each time period.

I am inclined to implement both and compare the results.

### Outcome (Productivity) Metrics

1. Number of commits in each time period
2. Number of lines added in each time period

Neither of them are perfect, but our Interrupted Time Series Analysis (ITS) should be able to somewhat handle the inherent problems of these metrics. For example, the project-level fixed effect dummies in the below specification should be able to account for commit volume differences across different projects.

### Model Specification

We use a pooled Interrupted Time Series Analysis (ITS) model, with project-level mixed effects and time-varying control variables, to estimate the effect of Cursor adoption on productivity.

$$
y_{it} = \beta_0 + \beta_1 X_{it} + \beta_2 T_{it} + \beta_3 X_{it} T_{it} + \sum_{j=1}^{n} \gamma_j Z^j_{it} + b_{0i} + \epsilon_{it}
$$

where $y_{it}$ is the outcome variable, $X_{it}$ is a binary variable indicating whether the user is using Cursor, $T_{it}$ is a categorical variable indicating the time period, $Z^j_{it}$ are time-varying control variables, $b_{0i}$ are repository-specific baseline deviations, and $\epsilon_{it}$ is an autocorrelated error term (we assume an $AR(1)$ process for simplicity).

## Libraries

```{r setup, message=FALSE}
library(readr)
library(lme4)
library(nlme)
library(ggplot2)
library(dplyr)
library(tidyr)
library(gridExtra)
library(modelsummary)
```

## Load Data

```{r}
its_repos <- read_csv("../data/its_repos.csv")
its_contributors <- read_csv("../data/its_contributors.csv")

# Drop the last time period for each repository and contributor
# This to avoid artifacts caused by incomplete periods
its_repos <- its_repos %>%
    group_by(repo_name) %>%
    mutate(is_last_timestep = time == max(time)) %>%
    filter(!is_last_timestep) %>%
    select(-is_last_timestep) %>%
    ungroup()
its_contributors <- its_contributors %>%
    group_by(author_name) %>%
    mutate(is_last_timestep = time == max(time)) %>%
    filter(!is_last_timestep) %>%
    select(-is_last_timestep) %>%
    ungroup()
```

## Visualization

```{r, fig.width=22.5, fig.height=15}
create_aligned_plot <- function(data, y_var, title, y_label) {
    # Center time around intervention
    data <- data %>%
        # Group by repo_name for repo data, or by both repo_name and author_name for contributor data
        group_by(if ("repo_name" %in% names(.) && !"author_name" %in% names(.)) {
            repo_name
        } else {
            across(c(repo_name, author_name))
        }) %>%
        mutate(
            # Calculate aligned time (0 = intervention point)
            aligned_time = time - time[which(intervention == 1)[1]],
            # Mark pre/post periods
            period = ifelse(intervention == 0, "Pre-Intervention", "Post-Intervention")
        ) %>%
        ungroup() %>%
        # Limit to time points >= -30
        filter(aligned_time >= -30 & aligned_time <= 30) %>%
        # Add a small constant to handle zeros for log scale
        mutate(!!y_var := pmax(get(y_var), 0.1))

    # Create box plot with log scale
    p <- ggplot(data, aes(x = factor(aligned_time), y = get(y_var), fill = period)) +
        geom_boxplot(position = "dodge", width = 0.7, outlier.size = 1) +
        geom_vline(
            xintercept = which(sort(unique(data$aligned_time)) == 0) - 0.5,
            linetype = "dashed", color = "black", linewidth = 1
        ) +
        scale_y_log10() +
        # Only show labels for every other time step
        scale_x_discrete(breaks = function(x) x[seq(1, length(x), by = 2)]) +
        labs(
            title = title,
            x = "Weeks Relative to Intervention (0 = Cursor Adoption)",
            y = paste(y_label, "(log scale)"),
            fill = "Period"
        ) +
        theme_minimal(base_size = 14) +
        theme(
            legend.position = "bottom",
            legend.text = element_text(size = 12),
            legend.title = element_text(size = 14),
            plot.title = element_text(size = 16, face = "bold"),
            axis.title = element_text(size = 14),
            axis.text = element_text(size = 12)
        ) +
        scale_fill_manual(values = c("Pre-Intervention" = "steelblue", "Post-Intervention" = "firebrick"))

    return(p)
}

# Repository-level visualizations
commits_repo_plot <- create_aligned_plot(
    its_repos,
    "commits",
    "Effect of Cursor Adoption on Repository Commits",
    "Number of Commits"
)

lines_repo_plot <- create_aligned_plot(
    its_repos,
    "lines_added",
    "Effect of Cursor Adoption on Repository Lines Added",
    "Lines Added"
)

bugs_plot <- create_aligned_plot(
    its_repos,
    "bugs",
    "Effect of Cursor Adoption on Bugs",
    "Number of Bugs"
)

vulnerabilities_plot <- create_aligned_plot(
    its_repos,
    "vulnerabilities",
    "Effect of Cursor Adoption on Vulnerabilities",
    "Number of Vulnerabilities"
)

code_smells_plot <- create_aligned_plot(
    its_repos,
    "code_smells",
    "Effect of Cursor Adoption on Code Smells",
    "Number of Code Smells"
)

duplicated_lines_plot <- create_aligned_plot(
    its_repos,
    "duplicated_lines_density",
    "Effect of Cursor Adoption on Duplicated Lines",
    "Duplicated Lines Density (%)"
)

comment_lines_plot <- create_aligned_plot(
    its_repos,
    "comment_lines_density",
    "Effect of Cursor Adoption on Comment Lines",
    "Comment Lines Density (%)"
)

complexity_plot <- create_aligned_plot(
    its_repos,
    "cognitive_complexity",
    "Effect of Cursor Adoption on Cognitive Complexity",
    "Cognitive Complexity"
)

tech_debt_plot <- create_aligned_plot(
    its_repos,
    "technical_debt",
    "Effect of Cursor Adoption on Technical Debt",
    "Technical Debt (minutes)"
)

# Display repository plots in a grid
grid.arrange(
    commits_repo_plot, lines_repo_plot, comment_lines_plot,
    bugs_plot, vulnerabilities_plot, code_smells_plot,
    duplicated_lines_plot, complexity_plot, tech_debt_plot,
    ncol = 3
)
```

## Repository-Level Models

```{r}
# Productivity models
model_commits_repo <- lme(
    fixed = log(commits + 1) ~ time + intervention + time_after_intervention + log(contributors + 1),
    random = ~ 1 | repo_name,
    correlation = corAR1(form = ~ time | repo_name),
    data = its_repos,
    na.action = na.omit
)

model_lines_repo <- lme(
    fixed = log(lines_added + 1) ~ time + intervention + time_after_intervention + log(contributors + 1),
    random = ~ 1 | repo_name,
    correlation = corAR1(form = ~ time | repo_name),
    data = its_repos,
    na.action = na.omit
)

# Quality models
model_bugs_repo <- lme(
    fixed = log(bugs + 1) ~ time + intervention + time_after_intervention + log(contributors + 1),
    random = ~ 1 | repo_name,
    correlation = corAR1(form = ~ time | repo_name),
    data = its_repos,
    na.action = na.omit
)

model_vulnerabilities_repo <- lme(
    fixed = log(vulnerabilities + 1) ~ time + intervention + time_after_intervention + log(contributors + 1),
    random = ~ 1 | repo_name,
    correlation = corAR1(form = ~ time | repo_name),
    data = its_repos,
    na.action = na.omit
)

model_code_smells_repo <- lme(
    fixed = log(code_smells + 1) ~ time + intervention + time_after_intervention + log(contributors + 1),
    random = ~ 1 | repo_name,
    correlation = corAR1(form = ~ time | repo_name),
    data = its_repos,
    na.action = na.omit
)

model_duplicated_lines_repo <- lme(
    fixed = log(duplicated_lines_density + 1) ~ time + intervention + time_after_intervention + log(contributors + 1),
    random = ~ 1 | repo_name,
    correlation = corAR1(form = ~ time | repo_name),
    data = its_repos,
    na.action = na.omit
)

model_comment_lines_repo <- lme(
    fixed = log(comment_lines_density + 1) ~ time + intervention + time_after_intervention + log(contributors + 1),
    random = ~ 1 | repo_name,
    correlation = corAR1(form = ~ time | repo_name),
    data = its_repos,
    na.action = na.omit
)

model_complexity_repo <- lme(
    fixed = log(cognitive_complexity + 1) ~ time + intervention + time_after_intervention + log(contributors + 1),
    random = ~ 1 | repo_name,
    correlation = corAR1(form = ~ time | repo_name),
    data = its_repos,
    na.action = na.omit
)

model_tech_debt_repo <- lme(
    fixed = log(technical_debt + 1) ~ time + intervention + time_after_intervention + log(contributors + 1),
    random = ~ 1 | repo_name,
    correlation = corAR1(form = ~ time | repo_name),
    data = its_repos,
    na.action = na.omit
)

# Create coefficient map with better labels
cm <- c(
    "time" = "Time",
    "intervention" = "Intervention",
    "time_after_intervention" = "Time After Intervention",
    "log(contributors + 1)" = "Contributors"
)

# Combine all repository-level models into one list
all_repo_models <- list(
    "Commits" = model_commits_repo,
    "Lines Added" = model_lines_repo,
    "Bugs" = model_bugs_repo,
    "Vulnerabilities" = model_vulnerabilities_repo,
    "Code Smells" = model_code_smells_repo,
    "Technical Debt" = model_tech_debt_repo,
    "Duplicated Lines" = model_duplicated_lines_repo,
    "Comment Lines" = model_comment_lines_repo,
    "Cognitive Complexity" = model_complexity_repo
)

# Generate combined model summary table
modelsummary(
    all_repo_models,
    title = "Repository-Level Interrupted Time Series Models",
    stars = TRUE,
    gof_map = c("nobs", "r.squared", "adj.r.squared"),
    coef_map = cm,
    output = "html"
)
```

## Contributor-Level Analysis

```{r, fig.width=15, fig.height=8}
# Contributor-level visualizations
commits_contrib_plot <- create_aligned_plot(
    its_contributors,
    "commits",
    "Effect of Cursor Adoption on Contributor Commits",
    "Number of Commits"
)

lines_contrib_plot <- create_aligned_plot(
    its_contributors,
    "lines_added",
    "Effect of Cursor Adoption on Contributor Lines Added",
    "Lines Added"
)

grid.arrange(
    commits_contrib_plot, lines_contrib_plot,
    ncol = 2
)
```

```{r}
# Create a unique ID for each author-repository combination
its_contributors <- its_contributors %>%
    mutate(author_repo_id = paste(author_name, repo_name, sep = "_"))

model_commits_contributor <- lme(
    fixed = log(commits + 1) ~ time + intervention + time_after_intervention,
    random = ~ 1 | author_repo_id,
    correlation = corAR1(form = ~ time | author_repo_id),
    data = its_contributors,
    na.action = na.omit
)

model_lines_contributor <- lme(
    fixed = log(lines_added + 1) ~ time + intervention + time_after_intervention,
    random = ~ 1 | author_repo_id,
    correlation = corAR1(form = ~ time | author_repo_id),
    data = its_contributors,
    na.action = na.omit
)

# Create a list of contributor models
contributor_models_list <- list(
    "Commits (Contributor)" = model_commits_contributor,
    "Lines (Contributor)" = model_lines_contributor
)

# Generate model summary table using modelsummary
modelsummary(
    contributor_models_list,
    title = "Contributor-Level Interrupted Time Series Models",
    stars = TRUE,
    gof_map = c("nobs", "r.squared", "adj.r.squared"),
    coef_map = cm,
    output = "html"
)
```

## Robustness Checks

DeepSeek suggested robustness checks, actual implementation TODO:

| Aspect                  | Tool/Method                          | Red Flag Resolution               |
|-------------------------|--------------------------------------|------------------------------------|
| Random effects validity | LRT, `ranef()`                       | Simplify random effects           |
| AR(1) adequacy          | ACF/PACF plots                      | Use `corCAR1` or higher-order AR  |
| Intervention timing     | Grouped `summarise()`               | Exclude poorly represented projects|
| Linearity               | LOESS smooth plots                  | Add non-linear terms              |
| Convergence             | `intervals()`, model warnings       | Reduce model complexity           |

```{r}

```
